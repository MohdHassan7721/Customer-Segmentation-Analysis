{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNPbebOW1hGVOnqh6kTX6bD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohdHassan7721/Customer-Segmentation-Analysis/blob/main/Revenue%20Forecasting%20%26%20Prediction%20Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Revenue Prediction using Linear Regression\n",
        "Create an interactive system to predict company revenue with Linear Regression, using variables like expenses and employee count. Includes data preprocessing, user input for predictions, and performance metrics (MAE, RMSE, R²).\n",
        "\n",
        "\n",
        "Approach to Solving the Problem\n",
        "\n",
        "1. Dataset Understanding\n",
        "Use data.csv as the input dataset.\n",
        "Target variable: Revenue\n",
        "Input features:\n",
        "Numerical: Marketing_Spend, R&D_Spend, Administration_Costs, Number_of_Employees\n",
        "Categorical: Region\n",
        "Dataset remains static and is used for both training and evaluation.\n",
        "2. Feature–Target Separation\n",
        "Separate the dataset into:\n",
        "X (features) → all columns except Revenue\n",
        "y (target) → Revenue\n",
        "This separation is mandatory before preprocessing and model training.\n",
        "3. Data Preprocessing\n",
        "Apply preprocessing using a ColumnTransformer.\n",
        "Numerical Features\n",
        "Handle missing values using mean imputation.\n",
        "Apply StandardScaler to normalize values.\n",
        "Categorical Features\n",
        "Handle missing values using most frequent category.\n",
        "Apply One-Hot Encoding to convert Region into numeric columns.\n",
        "Ignore unknown categories during prediction.\n",
        "4. Pipeline Construction\n",
        "Combine preprocessing and model training into a single pipeline.\n",
        "Pipeline flow:\n",
        "Preprocessing step\n",
        "Linear Regression model\n",
        "This ensures consistent transformations during training and prediction.\n",
        "5. Train–Test Split\n",
        "Split the dataset into:\n",
        "Training set\n",
        "Test set\n",
        "Use a fixed random state for reproducibility.\n",
        "6. Model Training\n",
        "Train the Linear Regression model using the training dataset.\n",
        "Model learns the relationship between business inputs and revenue.\n",
        "7. Model Evaluation\n",
        "Evaluate model performance on the test dataset.\n",
        "Display the following metrics:\n",
        "Mean Absolute Error (MAE)\n",
        "Root Mean Squared Error (RMSE)\n",
        "R-squared (R²)\n",
        "These metrics indicate prediction accuracy and model reliability.\n",
        "8. User Input Handling\n",
        "Accept user input for:\n",
        "Marketing Spend\n",
        "R&D Spend\n",
        "Administration Costs\n",
        "Number of Employees\n",
        "Region\n",
        "Validate numeric and categorical inputs before prediction.\n",
        "9. Revenue Prediction\n",
        "Convert user input into a DataFrame.\n",
        "Pass input through the trained pipeline.\n",
        "Display predicted revenue in readable format.\n",
        "10. Continuous Interaction Loop\n",
        "Allow users to make multiple predictions in a loop.\n",
        "Provide an option to exit the program cleanly.\n",
        "11. Program Termination\n",
        "Exit the program when the user chooses to stop.\n",
        "Ensure no further predictions are made after exit"
      ],
      "metadata": {
        "id": "ZRz7VRyAf48m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Business Revenue Prediction using Linear Regression:\n",
        "\n",
        "Objective:\n",
        "\n",
        "The objective of this project is to predict company revenue based on key business drivers such as:\n",
        "\n",
        "* Marketing Spend\n",
        "\n",
        "* R&D Spend\n",
        "\n",
        "* Administrative Costs\n",
        "\n",
        "* Number of Employees\n",
        "\n",
        "* Business Region\n",
        "\n",
        "This helps organizations:\n",
        "\n",
        "* Forecast revenue\n",
        "\n",
        "* Optimize spending decisions\n",
        "\n",
        "* Understand the impact of different business factors"
      ],
      "metadata": {
        "id": "e2HfFi4MM8yC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 1: Import Required Libraries\n",
        "* pandas → data loading and manipulation.\n",
        "\n",
        "* numpy → numerical computations.\n",
        "\n",
        "Explanation\n",
        "\n",
        "* train_test_split → model validation\n",
        "\n",
        "* LinearRegression → regression algorithm\n",
        "\n",
        "* MAE, RMSE, R² → model evaluation\n",
        "\n",
        "* StandardScaler → feature scaling\n",
        "\n",
        "* OneHotEncoder → categorical encoding\n",
        "\n",
        "* ColumnTransformer + Pipeline → clean, production-ready preprocessing"
      ],
      "metadata": {
        "id": "fxXdPsY-Nesk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EtAItGprMbcY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n"
      ],
      "metadata": {
        "id": "wrrg0y1YOZHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 2: Load and Preprocess the Dataset.\n",
        "***Machine learning models require:***\n",
        "\n",
        "* Clean data\n",
        "\n",
        "* Numerical inputs\n",
        "\n",
        "* Proper handling of missing values.\n",
        "\n",
        "***Identify Numerical and Categorical Features:***\n",
        "\n",
        "* Numerical → scaling required.\n",
        "\n",
        "* Categorical → encoding required.\n",
        "\n",
        "***Numerical Data Preprocessing Pipeline.***\n",
        "\n",
        "Linear Regression is sensitive to:\n",
        "\n",
        "* Missing values.\n",
        "\n",
        "* Feature scale.\n",
        "\n",
        "**Explanation:**\n",
        "\n",
        "* Mean imputation → handles missing numerical values\n",
        "\n",
        "* Standard scaling → ensures equal feature contribution\n",
        "\n",
        "***Categorical Data Preprocessing Pipeline.***\n",
        "\n",
        "**Explanation:**\n",
        "\n",
        "* Most frequent imputation → handles missing categories\n",
        "\n",
        "* One-Hot Encoding → converts regions into binary features\n",
        "\n",
        "* handle_unknown='ignore' → prevents runtime errors"
      ],
      "metadata": {
        "id": "xH-7-RFZOfZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Load and preprocess the dataset\n",
        "def load_and_preprocess(file_path):\n",
        "    data = pd.read_csv(file_path)\n",
        "\n",
        "    # Separate features and target\n",
        "    X = data.drop('Revenue', axis=1)\n",
        "    y = data['Revenue']\n",
        "\n",
        "    # Identify columns\n",
        "    numerical_features = [\n",
        "        'Marketing_Spend',\n",
        "        'R&D_Spend',\n",
        "        'Administration_Costs',\n",
        "        'Number_of_Employees'\n",
        "    ]\n",
        "\n",
        "    categorical_features = ['Region']\n",
        "\n",
        "    # Numerical preprocessing\n",
        "    numerical_pipeline = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='mean')),\n",
        "        ('scaler', StandardScaler())\n",
        "    ])\n",
        "\n",
        "    # Categorical preprocessing\n",
        "    categorical_pipeline = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "    ])\n",
        "\n",
        "    # Combine preprocessing\n",
        "    preprocessor = ColumnTransformer(transformers=[\n",
        "        ('num', numerical_pipeline, numerical_features),\n",
        "        ('cat', categorical_pipeline, categorical_features)\n",
        "    ])\n",
        "\n",
        "    return X, y, preprocessor\n"
      ],
      "metadata": {
        "id": "1Q9d97hfYDDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 3: Train the Linear Regression Model.\n",
        " **Explanation:**\n",
        "\n",
        "* Preprocessing + model combined into one pipeline\n",
        "\n",
        "* Prevents data leakage\n",
        "\n",
        "* Makes deployment easier"
      ],
      "metadata": {
        "id": "-LS7-rTxTO_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(X_train, y_train, preprocessor):\n",
        "    model = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('regressor', LinearRegression())\n",
        "    ])\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "kY2VJnaVTfqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 4: Model Evaluation.\n",
        "* MAE → average prediction error.\n",
        "\n",
        "* RMSE → penalizes large errors.\n",
        "\n",
        "* R² Score → variance explained by the model."
      ],
      "metadata": {
        "id": "fhhyoR84TvYl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Evaluate model performance\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    print(\"\\nModel Evaluation Metrics:\")\n",
        "    print(f\"MAE  : {mae:.2f}\")\n",
        "    print(f\"RMSE : {rmse:.2f}\")\n",
        "    print(f\"R\\u00b2   : {r2:.3f}\")"
      ],
      "metadata": {
        "id": "jd_gwZNLUCo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 5: Revenue Prediction for New Inputs.\n",
        " **Explanation:**\n",
        "\n",
        "* Accepts dynamic user inputs\n",
        "\n",
        "* Applies same preprocessing automatically\n",
        "\n",
        "* Outputs predicted revenue"
      ],
      "metadata": {
        "id": "kJ0bhnvTUgqr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " #Step 5: Predict revenue for new input\n",
        "def predict_revenue(model, user_input):\n",
        "    input_df = pd.DataFrame([user_input])\n",
        "    prediction = model.predict(input_df)\n",
        "    print(f\"\\nPredicted Revenue: {prediction[0]:.2f}\")"
      ],
      "metadata": {
        "id": "-zKC2YIoUyqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3__0A0X-g3ME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 6: Train-Test Split and Execution Flow.\n",
        "* 80% training\n",
        "\n",
        "* 20% testing\n",
        "\n",
        "* Reproducible results"
      ],
      "metadata": {
        "id": "m6SoGkSwU_Ku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Main program\n",
        "def main():\n",
        "    file_path = \"Revenue.csv\"  # upload this file if using Colab\n",
        "\n",
        "    X, y, preprocessor = load_and_preprocess(file_path)\n",
        "\n",
        "    # Train-test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Train model\n",
        "    model = train_model(X_train, y_train, preprocessor)\n",
        "\n",
        "    # Evaluate model\n",
        "    evaluate_model(model, X_test, y_test)\n",
        "\n",
        "    # Interactive prediction loop\n",
        "    while True:\n",
        "        print(\"\\nEnter business details (or type 'exit' to stop):\")\n",
        "\n",
        "        choice = input(\"Continue? (yes/exit): \").lower()\n",
        "        if choice == 'exit':\n",
        "            print(\"Program terminated.\")\n",
        "            break\n",
        "\n",
        "        user_input = {\n",
        "            'Marketing_Spend': float(input(\"Marketing Spend: \")),\n",
        "            'R&D_Spend': float(input(\"R&D Spend: \")),\n",
        "            'Administration_Costs': float(input(\"Administration Costs: \")),\n",
        "            'Number_of_Employees': int(input(\"Number of Employees: \")),\n",
        "            'Region': input(\"Region (North America / Europe / Asia): \")\n",
        "        }\n",
        "\n",
        "        predict_revenue(model, user_input)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "gkTqcIrAVQGB",
        "outputId": "6166fedc-4686-4205-9aba-793ab852e95b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'Revenue.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1044349257.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-1044349257.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Revenue.csv\"\u001b[0m  \u001b[0;31m# upload this file if using Colab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_and_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Train-test split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1221430090.py\u001b[0m in \u001b[0;36mload_and_preprocess\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Step 2: Load and preprocess the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_and_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Separate features and target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Revenue.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdb2f4d9"
      },
      "source": [
        "## Step 7: File Upload and Main Program Execution Control"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea41b88c"
      },
      "source": [
        "This code block ensures that the `Revenue.csv` file, which is crucial for the model, is available in the Colab environment.\n",
        "\n",
        "- It first checks if `Revenue.csv` already exists in the current directory.\n",
        "- If the file is *not* found, it prompts the user to upload it using `files.upload()`.\n",
        "- After a successful upload (or if the file already existed), it proceeds to call the `main()` function, which orchestrates the entire revenue prediction workflow (data loading, preprocessing, model training, evaluation, and interactive prediction)."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jYrUv0IJiFQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "file_name_revenue = 'Revenue.csv'\n",
        "\n",
        "# Check if the file already exists\n",
        "if not os.path.exists(file_name_revenue):\n",
        "    print(f\"'{file_name_revenue}' not found. Please upload the file.\")\n",
        "    try:\n",
        "        # Prompt user to upload the file\n",
        "        uploaded = files.upload()\n",
        "\n",
        "        if file_name_revenue not in uploaded:\n",
        "            print(f\"Error: '{file_name_revenue}' was not uploaded. Please ensure you select the correct file.\")\n",
        "        else:\n",
        "            print(f\"'{file_name_revenue}' uploaded successfully. Running the main function for Revenue Prediction...\")\n",
        "            # Call the main function defined in the notebook for Revenue Prediction (cell 5NCgfYhychDY)\n",
        "            # Ensure the main function for Revenue Prediction is called from its respective cell's scope or properly imported\n",
        "            main() # This calls the main function from the Revenue Prediction script\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during file upload: {e}\")\n",
        "else:\n",
        "    print(f\"'{file_name_revenue}' already exists. Running the main function for Revenue Prediction...\")\n",
        "    # Call the main function defined in the notebook for Revenue Prediction\n",
        "    main() # This calls the main function from the Revenue Prediction script"
      ],
      "metadata": {
        "id": "AG8sJak4iF4s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "outputId": "f0ec7106-aace-4eef-dc49-71cc5b41dba8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Revenue.csv' not found. Please upload the file.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7aa7d8fe-43fb-457f-8bfa-87224accec4a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7aa7d8fe-43fb-457f-8bfa-87224accec4a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Revenue.csv to Revenue.csv\n",
            "'Revenue.csv' uploaded successfully. Running the main function for Revenue Prediction...\n",
            "\n",
            "Model Evaluation Metrics:\n",
            "MAE  : 6648.40\n",
            "RMSE : 8363.06\n",
            "R²   : 0.933\n",
            "\n",
            "Enter business details (or type 'exit' to stop):\n",
            "Continue? (yes/exit): exit\n",
            "Program terminated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HZAYifkTdKOo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}